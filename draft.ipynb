{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597054699130",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict\n",
    "\n",
    "from models import build_model\n",
    "from data import DataManger_Epoch, DataManger_Episode\n",
    "from logger import setup_logging\n",
    "from utils import read_config, rmdir, summary, array_interweave, COLOR\n",
    "from evaluators import recognition_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_test(logger_func, attribute_name: list, weight, result_label, result_instance):\n",
    "    r\"\"\" log test from result\n",
    "    \"\"\"\n",
    "    logger_func('instance-based metrics:')\n",
    "    logger_func('accuracy: %0.4f' % result_instance.accuracy)\n",
    "    logger_func('precision: %0.4f' % result_instance.precision)\n",
    "    logger_func('recall: %0.4f' % result_instance.recall)\n",
    "    logger_func('f1_score: %0.4f' % result_instance.f1_score)\n",
    "\n",
    "    logger_func('class-based metrics:')\n",
    "    result = np.stack([result_label.accuracy, result_label.mean_accuracy, result_label.precision, result_label.recall, result_label.f1_score], axis=0)\n",
    "    result = np.around(result*100, 2)\n",
    "    result = result.transpose()\n",
    "    row_format =\"{:>20}\" + \"{:>10}\"*6\n",
    "    \n",
    "    logger_func(row_format.format('attribute', 'weight', 'accuracy', 'mA', 'precision', 'recall', 'f1_score'))\n",
    "    \n",
    "    logger_func(row_format.format(*['-']*7))\n",
    "    \n",
    "    for i in range(len(attribute_name)):\n",
    "        logger_func(row_format.format(attribute_name[i], np.around(weight[i]*100, 2), *result[i].tolist()))\n",
    "\n",
    "    logger_func(row_format.format(*['-']*7))\n",
    "    \n",
    "    logger_func(row_format.format(\n",
    "        'mean',\n",
    "        '-',\n",
    "        round(np.mean(result_label.accuracy)*100, 2),\n",
    "        round(np.mean(result_label.mean_accuracy)*100, 2),\n",
    "        round(np.mean(result_label.precision)*100, 2),\n",
    "        round(np.mean(result_label.recall)*100, 2),\n",
    "        round(np.mean(result_label.f1_score)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_class_based(logger_func, attribute_name, weight, result_label1, result_label2, color=COLOR.BOLD):\n",
    "    \n",
    "    logger_func('class-based metrics:')\n",
    "    result1 = np.stack([result_label1.accuracy, result_label1.mean_accuracy, result_label1.precision, result_label1.recall, result_label1.f1_score], axis=0)\n",
    "    result1 = np.around(result1*100, 2)\n",
    "    result1 = result1.transpose()\n",
    "\n",
    "    result2 = np.stack([result_label2.accuracy, result_label2.mean_accuracy, result_label2.precision, result_label2.recall, result_label2.f1_score], axis=0)\n",
    "    result2 = np.around(result2*100, 2)\n",
    "    result2 = result2.transpose()\n",
    "\n",
    "    row_format = \"{:>20}{:>12}{:>15}{:>12}{:>20}{:>14}{:>18}\"\n",
    "    logger_func(row_format.format('attribute', 'weight', 'accuracy', 'mA', 'precision', 'recall', 'f1_score'))\n",
    "    \n",
    "    logger_func(row_format.format(*['-']*7))\n",
    "\n",
    "    for i in range(len(attribute_name)):\n",
    "        row_format = \"{:>20}\" + \"{:>12}\"\n",
    "        for j in range(5):\n",
    "            if result1[i][j] > result2[i][j]:\n",
    "                row_format += color + \"{:>10}\" + COLOR.END +\"|{:>5}\"\n",
    "            elif result1[i][j] < result2[i][j]:\n",
    "                row_format += \"{:>10}|\" + color + \"{:>5}\" + COLOR.END\n",
    "            else:\n",
    "                row_format += color + \"{:>10}\" + COLOR.END + \"|\" + color + \"{:>5}\" + COLOR.END\n",
    "        logger_func(row_format.format(attribute_name[i], np.around(weight[i]*100, 2), *array_interweave(result1[i], result2[i]).tolist()))\n",
    "\n",
    "    row_format = \"{:>20}\" + \"{:>12}\" + \"{:>10}|{:>5}\"*5\n",
    "    logger_func(row_format.format(*['-']*12))\n",
    "    \n",
    "    mean_result1 = np.around(np.mean(np.array([result_label1.accuracy, result_label1.mean_accuracy, result_label1.precision, result_label1.recall, result_label1.f1_score]), axis=1)*100, 2)\n",
    "    \n",
    "    mean_result2 = np.around(np.mean(np.array([result_label2.accuracy, result_label2.mean_accuracy, result_label2.precision, result_label2.recall, result_label2.f1_score]), axis=1)*100, 2)\n",
    "    \n",
    "    row_format = \"{:>20}\" + \"{:>12}\"\n",
    "    for i in range(5):\n",
    "        if mean_result1[i] > mean_result2[i]:\n",
    "            row_format += color + \"{:>10}\" + COLOR.END +\"|{:>5}\"\n",
    "        elif mean_result1[i] < mean_result2[i]:\n",
    "            row_format += \"{:>10}|\" + color + \"{:>5}\" + COLOR.END\n",
    "        else:\n",
    "            row_format += color + \"{:>10}\" + COLOR.END + \"|\" + color + \"{:>5}\" + COLOR.END\n",
    "\n",
    "    logger_func(row_format.format(\n",
    "        'mean',\n",
    "        '-',\n",
    "        round(np.mean(result_label1.accuracy)*100, 2),\n",
    "        round(np.mean(result_label2.accuracy)*100, 2),\n",
    "        round(np.mean(result_label1.mean_accuracy)*100, 2),\n",
    "        round(np.mean(result_label2.mean_accuracy)*100, 2),\n",
    "        round(np.mean(result_label1.precision)*100, 2),\n",
    "        round(np.mean(result_label2.precision)*100, 2),\n",
    "        round(np.mean(result_label1.recall)*100, 2),\n",
    "        round(np.mean(result_label2.recall)*100, 2),\n",
    "        round(np.mean(result_label1.f1_score)*100, 2),\n",
    "        round(np.mean(result_label2.f1_score)*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(config, datamanager, logger_func):\n",
    "    cfg_trainer = config['trainer_colab'] if config['colab'] == True else config['trainer']\n",
    "\n",
    "    use_gpu = cfg_trainer['n_gpu'] > 0 and torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_gpu else 'cpu')\n",
    "    map_location = \"cuda:0\" if use_gpu else torch.device('cpu')\n",
    "    \n",
    "    model, _ = build_model(config, num_classes=len(datamanager.datasource.get_attribute()))\n",
    "\n",
    "    logger_func('Loading checkpoint: {} ...'.format(config['resume']))\n",
    "    checkpoint = torch.load(config['resume'], map_location=map_location)\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with tqdm(total=len(datamanager.get_dataloader('test'))) as epoch_pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, _labels) in enumerate(datamanager.get_dataloader('test')):\n",
    "                data, _labels = data.to(device), _labels.to(device)\n",
    "\n",
    "                out = model(data)\n",
    "\n",
    "                _preds = torch.sigmoid(out)\n",
    "                preds.append(_preds)\n",
    "                labels.append(_labels)\n",
    "                epoch_pbar.update(1)\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    preds = preds.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    result_label, result_instance = recognition_metrics(labels, preds)\n",
    "\n",
    "    return result_label, result_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading...\nDownloaded!\nDownloading...\nDownloaded!\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-be268e0ac98f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# model1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mresult_label1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_instance1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamanager1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# model 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "config1 = \"config/baseline_peta.yml\"\n",
    "config2 = \"config/episode_peta.yml\"\n",
    "\n",
    "resume1 = \"/content/drive/Shared drives/REID/HIEN/Models/OSNet_Person_Attribute_Refactor/checkpoints/0731_232453/model_best_accuracy.pth\"\n",
    "resume2 = \"/content/drive/Shared drives/REID/HIEN/Models/person_attribute_recognition/checkpoints/0809_231322/model_best_accuracy.pth\"\n",
    "\n",
    "config1 = read_config(config1)\n",
    "config1.update({'resume': resume1})\n",
    "config1.update({'colab': True})\n",
    "\n",
    "config2 = read_config(config2)\n",
    "config2.update({'resume': resume2})\n",
    "config2.update({'colab': True})\n",
    "\n",
    "datamanager1 = DataManger_Epoch(config1['data'])\n",
    "datamanager2 = DataManger_Episode(config2['data'])\n",
    "\n",
    "weight = datamanager1.datasource.get_weight('train')\n",
    "\n",
    "# model1\n",
    "result_label1, result_instance1 = test(config1, datamanager1, print)\n",
    "\n",
    "# model 2\n",
    "result_label2, result_instance2 = test(config2, datamanager2, print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "class-based metrics:\n           attribute      weight       accuracy          mA           precision        recall          f1_score\n                   -           -              -           -                   -             -                 -\n        accessoryHat       10.47\u001b[94m      98.2\u001b[0m|97.79     93.88|\u001b[94m94.64\u001b[0m\u001b[94m     92.24\u001b[0m|86.69     88.55|\u001b[94m90.76\u001b[0m\u001b[94m     90.36\u001b[0m|88.68\n    accessoryMuffler        8.42\u001b[94m     99.13\u001b[0m|98.86      96.5|\u001b[94m 97.0\u001b[0m\u001b[94m     96.09\u001b[0m|91.73     93.35|\u001b[94m94.78\u001b[0m\u001b[94m      94.7\u001b[0m|93.23\n    accessoryNothing       74.56\u001b[94m     92.67\u001b[0m|92.38      87.6|\u001b[94m88.04\u001b[0m      93.1|\u001b[94m93.58\u001b[0m\u001b[94m     97.53\u001b[0m|96.53\u001b[94m     95.26\u001b[0m|95.04\n accessorySunglasses         3.0\u001b[94m     97.91\u001b[0m|96.61     70.88|\u001b[94m78.44\u001b[0m\u001b[94m      73.6\u001b[0m|43.29      42.2|\u001b[94m59.17\u001b[0m\u001b[94m     53.64\u001b[0m| 50.0\n            hairLong       23.62\u001b[94m      94.5\u001b[0m|93.42     92.06|\u001b[94m 92.5\u001b[0m\u001b[94m      89.2\u001b[0m| 83.1     87.42|\u001b[94m90.74\u001b[0m\u001b[94m      88.3\u001b[0m|86.75\n     upperBodyCasual       85.36\u001b[94m     94.78\u001b[0m|94.43     85.72|\u001b[94m86.15\u001b[0m     95.53|\u001b[94m95.75\u001b[0m\u001b[94m     98.49\u001b[0m|97.83\u001b[94m     96.99\u001b[0m|96.78\n     upperBodyFormal       13.31\u001b[94m     95.51\u001b[0m|95.16     86.52|\u001b[94m87.45\u001b[0m\u001b[94m     90.12\u001b[0m|85.07     74.28|\u001b[94m76.96\u001b[0m\u001b[94m     81.44\u001b[0m|80.81\n     upperBodyJacket        7.16\u001b[94m     96.01\u001b[0m|94.14     79.25|\u001b[94m82.74\u001b[0m\u001b[94m     78.38\u001b[0m|56.81     59.74|\u001b[94m69.48\u001b[0m\u001b[94m      67.8\u001b[0m|62.51\n       upperBodyLogo        4.11\u001b[94m     96.86\u001b[0m|94.67     76.97|\u001b[94m85.72\u001b[0m\u001b[94m     60.52\u001b[0m|40.25     55.41|\u001b[94m76.01\u001b[0m\u001b[94m     57.85\u001b[0m|52.63\n      upperBodyPlaid        2.68\u001b[94m     98.74\u001b[0m|97.59     86.18|\u001b[94m91.34\u001b[0m\u001b[94m     78.31\u001b[0m|53.09     72.91|\u001b[94m84.73\u001b[0m\u001b[94m     75.51\u001b[0m|65.28\nupperBodyShortSleeve       14.04\u001b[94m     95.37\u001b[0m|94.26     90.96|\u001b[94m92.22\u001b[0m\u001b[94m     83.24\u001b[0m|75.27     84.77|\u001b[94m89.36\u001b[0m\u001b[94m      84.0\u001b[0m|81.71\nupperBodyThinStripes        1.84\u001b[94m     98.79\u001b[0m|98.38     73.25|\u001b[94m79.67\u001b[0m\u001b[94m     70.24\u001b[0m|51.01     46.83|\u001b[94m60.32\u001b[0m\u001b[94m     56.19\u001b[0m|55.27\n     upperBodyTshirt        8.52\u001b[94m     95.66\u001b[0m| 93.7     84.01|\u001b[94m89.39\u001b[0m\u001b[94m     76.45\u001b[0m|58.78      70.0|\u001b[94m84.22\u001b[0m\u001b[94m     73.08\u001b[0m|69.24\n      upperBodyOther       45.42\u001b[94m      87.8\u001b[0m|87.16\u001b[94m     87.48\u001b[0m|87.03\u001b[94m     88.61\u001b[0m|86.07     83.97|\u001b[94m85.62\u001b[0m\u001b[94m     86.23\u001b[0m|85.84\n      upperBodyVNeck        1.23\u001b[94m      99.2\u001b[0m| 98.3     63.11|\u001b[94m78.12\u001b[0m\u001b[94m      91.3\u001b[0m|32.62     26.25|\u001b[94m 57.5\u001b[0m     40.78|\u001b[94m41.63\u001b[0m\n     lowerBodyCasual       86.16\u001b[94m      95.0\u001b[0m| 94.8     85.28|\u001b[94m86.16\u001b[0m     95.61|\u001b[94m95.94\u001b[0m\u001b[94m     98.73\u001b[0m|98.12\u001b[94m     97.14\u001b[0m|97.02\n     lowerBodyFormal       13.64\u001b[94m     95.21\u001b[0m|94.93     85.74|\u001b[94m86.46\u001b[0m\u001b[94m     90.56\u001b[0m|86.47     72.67|\u001b[94m74.78\u001b[0m\u001b[94m     80.64\u001b[0m|80.21\n      lowerBodyJeans       30.73\u001b[94m     90.16\u001b[0m|88.83     87.91|\u001b[94m88.41\u001b[0m\u001b[94m     85.02\u001b[0m|78.43     82.16|\u001b[94m87.34\u001b[0m\u001b[94m     83.57\u001b[0m|82.65\n     lowerBodyShorts        3.48\u001b[94m     97.72\u001b[0m|96.25     81.64|\u001b[94m86.79\u001b[0m\u001b[94m     67.74\u001b[0m|47.17     64.37|\u001b[94m76.63\u001b[0m\u001b[94m     66.01\u001b[0m|58.39\n lowerBodyShortSkirt        4.63\u001b[94m     97.59\u001b[0m|95.55      84.5|\u001b[94m89.54\u001b[0m\u001b[94m     75.93\u001b[0m|51.14     70.09|\u001b[94m82.91\u001b[0m\u001b[94m     72.89\u001b[0m|63.26\n   lowerBodyTrousers       51.21\u001b[94m     87.05\u001b[0m|86.76\u001b[94m     87.03\u001b[0m|86.72\u001b[94m     87.45\u001b[0m| 86.8     87.67|\u001b[94m 87.9\u001b[0m\u001b[94m     87.56\u001b[0m|87.34\nfootwearLeatherShoes       29.83\u001b[94m     91.96\u001b[0m|90.92     89.04|\u001b[94m89.29\u001b[0m\u001b[94m     89.51\u001b[0m|83.78     82.03|\u001b[94m85.37\u001b[0m\u001b[94m     85.61\u001b[0m|84.57\n     footwearSandals        2.16\u001b[94m     98.09\u001b[0m|96.93     72.47|\u001b[94m81.41\u001b[0m\u001b[94m     49.62\u001b[0m|33.94     45.83|\u001b[94m65.28\u001b[0m\u001b[94m     47.65\u001b[0m|44.66\n       footwearShoes       35.66\u001b[94m     83.28\u001b[0m|81.59\u001b[94m     82.36\u001b[0m|81.39\u001b[94m      76.1\u001b[0m|72.18     78.98|\u001b[94m80.64\u001b[0m\u001b[94m     77.52\u001b[0m|76.18\n     footwearSneaker       21.73\u001b[94m     88.37\u001b[0m|85.99     80.16|\u001b[94m83.86\u001b[0m\u001b[94m     78.19\u001b[0m|64.72     65.49|\u001b[94m80.06\u001b[0m     71.28|\u001b[94m71.58\u001b[0m\n    carryingBackpack       19.53\u001b[94m     92.41\u001b[0m|90.42     88.01|\u001b[94m89.27\u001b[0m\u001b[94m     80.71\u001b[0m|70.82     80.76|\u001b[94m87.37\u001b[0m\u001b[94m     80.73\u001b[0m|78.23\n       carryingOther       19.84\u001b[94m     88.45\u001b[0m|85.88     78.68|\u001b[94m80.66\u001b[0m\u001b[94m     76.02\u001b[0m|63.13     62.31|\u001b[94m71.91\u001b[0m\u001b[94m     68.49\u001b[0m|67.24\ncarryingMessengerBag       29.03\u001b[94m     88.83\u001b[0m|87.45     85.71|\u001b[94m86.16\u001b[0m\u001b[94m     83.63\u001b[0m|76.93     77.93|\u001b[94m82.95\u001b[0m\u001b[94m     80.68\u001b[0m|79.82\n     carryingNothing       27.77\u001b[94m     89.66\u001b[0m|88.07     85.79|\u001b[94m87.05\u001b[0m\u001b[94m     83.93\u001b[0m|75.06     77.19|\u001b[94m84.79\u001b[0m\u001b[94m     80.42\u001b[0m|79.63\n carryingPlasticBags         7.8\u001b[94m     97.57\u001b[0m|96.36     87.87|\u001b[94m90.03\u001b[0m\u001b[94m     90.49\u001b[0m| 73.4     76.41|\u001b[94m82.56\u001b[0m\u001b[94m     82.85\u001b[0m|77.72\n      personalLess30       49.19\u001b[94m     88.87\u001b[0m|88.39\u001b[94m     88.86\u001b[0m|88.38\u001b[94m     88.06\u001b[0m|87.26\u001b[94m     90.13\u001b[0m|\u001b[94m90.13\u001b[0m\u001b[94m     89.09\u001b[0m|88.67\n      personalLess45       33.58\u001b[94m     87.54\u001b[0m|86.25     85.08|\u001b[94m85.34\u001b[0m\u001b[94m     82.14\u001b[0m|76.38     78.21|\u001b[94m82.79\u001b[0m\u001b[94m     80.13\u001b[0m|79.46\n      personalLess60       10.21\u001b[94m     96.26\u001b[0m|95.05     87.57|\u001b[94m87.75\u001b[0m\u001b[94m     85.41\u001b[0m|74.54     76.64|\u001b[94m78.56\u001b[0m\u001b[94m     80.78\u001b[0m| 76.5\n    personalLarger60        6.15\u001b[94m     99.32\u001b[0m|98.83     95.88|\u001b[94m96.54\u001b[0m\u001b[94m     96.58\u001b[0m|87.65     91.97|\u001b[94m93.93\u001b[0m\u001b[94m     94.22\u001b[0m|90.68\n        personalMale       55.16\u001b[94m      93.8\u001b[0m|93.51\u001b[94m      93.7\u001b[0m|93.49     93.85|\u001b[94m94.34\u001b[0m\u001b[94m     94.86\u001b[0m|93.73\u001b[94m     94.35\u001b[0m|94.04\n                   -           -         -|    -         -|    -         -|    -         -|    -         -|    -\n                mean           -\u001b[94m     93.95\u001b[0m|92.85     84.79|\u001b[94m87.29\u001b[0m\u001b[94m     83.24\u001b[0m|71.81     75.32|\u001b[94m82.34\u001b[0m\u001b[94m     78.39\u001b[0m|76.09\n"
    }
   ],
   "source": [
    "compare_class_based(print, datamanager1.datasource.get_attribute(), weight, result_label1, result_label2, COLOR.BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.10473684 0.08421053 0.74557894 0.03       0.23621053 0.8535789\n 0.13305263 0.07157895 0.04105263 0.02684211 0.14042105 0.01842105\n 0.08515789 0.45421052 0.01231579 0.86157894 0.13642105 0.30726317\n 0.0348421  0.04631579 0.5121053  0.2983158  0.02157895 0.35663158\n 0.21726316 0.19526316 0.19842105 0.29031578 0.2776842  0.078\n 0.49189472 0.33578947 0.10210526 0.06147368 0.55157894]\n"
    }
   ],
   "source": [
    "weight = datamanager1.datasource.get_weight('train')\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.multinomial import Multinomial\n",
    "m = Multinomial(32, torch.exp(1-torch.tensor(weight)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_name = datamanager1.datasource.get_attribute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['footwearLeatherShoes', 'lowerBodyShortSkirt', 'carryingOther', 'personalMale', 'footwearShoes', 'upperBodyPlaid', 'upperBodyJacket', 'lowerBodyTrousers']\n"
    }
   ],
   "source": [
    "import random\n",
    "selected_attribute = random.sample(attribute_name, 8)\n",
    "print(selected_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0., 0., 1., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n        0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-7387f2987592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36mrsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mare\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Multinomial(probs=torch.exp(1-torch.tensor(weight))).rsample(torch.Size([8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 1,  8, 10, 25, 20, 16,  0, 29])"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "torch.multinomial(torch.exp(1-torch.tensor(weight)), 8, replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'collections.defaultdict' and 'int'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-25839fecb298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'collections.defaultdict' and 'int'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "from collections import defaultdict\n",
    "result = defaultdict(int)\n",
    "for _ in range(10000):\n",
    "    temp = torch.multinomial(torch.exp(1-torch.tensor(weight)), 8, replacement=True)\n",
    "    for key, value in collections.Counter(temp.numpy()).items():\n",
    "        result[key] += value\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}